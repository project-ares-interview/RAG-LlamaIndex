import os
import json
import sys
from dotenv import load_dotenv
from openai import AzureOpenAI
from unidecode import unidecode
import re
import traceback

# RAG ì‹œìŠ¤í…œ í´ë˜ìŠ¤ë¥¼ ì„í¬íŠ¸í•©ë‹ˆë‹¤.
from new_azure_rag_llamaindex import AzureBlobRAGSystem
# ì›¹ ê²€ìƒ‰ ë„êµ¬ ì„í¬íŠ¸
from tool_code import google_search

def extract_json_from_response(text: str) -> str:
    """AIì˜ ì‘ë‹µ í…ìŠ¤íŠ¸ì—ì„œ ìˆœìˆ˜í•œ JSON ë¶€ë¶„ë§Œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    # ì½”ë“œ ë¸”ë¡ì—ì„œ JSON ì¶”ì¶œ
    match = re.search(r'```json\s*(\{.*?\})\s*```', text, re.DOTALL)
    if match:
        return match.group(1)
    # í…ìŠ¤íŠ¸ì—ì„œ ê°€ì¥ í° JSON ê°ì²´ ì¶”ì¶œ
    match = re.search(r'\{.*\}', text, re.DOTALL)
    if match:
        return match.group(0)
    return text

class RAGInterviewBot:
    """[ìµœì¢…] í‰ê°€ ê²°ê³¼ë¥¼ ë©´ì ‘ ì¢…ë£Œ í›„ ì¼ê´„ ì œê³µí•˜ëŠ” ë©´ì ‘ ì‹œìŠ¤í…œ"""

    def __init__(self, company_name: str, job_title: str, container_name: str, index_name: str):
        print("ğŸ¤– RAG ì „ìš© ì‚¬ì—… ë¶„ì„ ë©´ì ‘ ì‹œìŠ¤í…œ ì´ˆê¸°í™”...")
        self.company_name = company_name
        self.job_title = job_title

        load_dotenv(dotenv_path=".env.keys", override=True)
        self.client = AzureOpenAI(
            azure_endpoint=os.getenv('AZURE_OPENAI_ENDPOINT'),
            api_key=os.getenv('AZURE_OPENAI_KEY'),
            api_version=os.getenv('API_VERSION', '2024-02-15-preview')
        )
        self.model = os.getenv('AZURE_OPENAI_MODEL', 'gpt-4o')

        print("\nğŸ“Š Azure ì‚¬ì—… ë¶„ì„ RAG ì‹œìŠ¤í…œ ì—°ë™...")
        self.rag_system = None
        self.rag_ready = False
        try:
            self.rag_system = AzureBlobRAGSystem(container_name=container_name, index_name=index_name)
            
            blobs = list(self.rag_system.container_client.list_blobs())
            if not blobs:
                print(f"âš ï¸ ê²½ê³ : Azure Blob ì»¨í…Œì´ë„ˆ '{container_name}'ì— ë¶„ì„í•  íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
                return

            print(f"âœ… Azure RAG ì‹œìŠ¤í…œ ì¤€ë¹„ ì™„ë£Œ. {len(blobs)}ê°œì˜ ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•©ë‹ˆë‹¤.")
            if input("Azure AI Search ì¸ë±ìŠ¤ë¥¼ ë™ê¸°í™”í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (y/n): ").lower() == 'y':
                self.rag_system.sync_index()
            self.rag_ready = True

        except Exception as e:
            print(f"âŒ RAG ì‹œìŠ¤í…œ ì—°ë™ ì‹¤íŒ¨: {e}")

    def generate_questions(self, num_questions: int = 3) -> list:
        """RAG ê¸°ë°˜ìœ¼ë¡œ ì‚¬ì—… í˜„í™© ì‹¬ì¸µ ì§ˆë¬¸ ìƒì„±"""
        if not self.rag_ready: return []
        print(f"\nğŸ§  {self.company_name} ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì¤‘...")
        try:
            business_info = self.rag_system.query(f"{self.company_name}ì˜ í•µì‹¬ ì‚¬ì—…, ìµœê·¼ ì‹¤ì , ì£¼ìš” ë¦¬ìŠ¤í¬ì— ëŒ€í•´ ìš”ì•½í•´ì¤˜.")
            prompt = f"""
            ë‹¹ì‹ ì€ {self.company_name}ì˜ {self.job_title} ì§ë¬´ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
            ì•„ë˜ì˜ ìµœì‹  ì‚¬ì—… í˜„í™© ë°ì´í„°ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì˜ ë¶„ì„ë ¥ê³¼ ì „ëµì  ì‚¬ê³ ë¥¼ ê²€ì¦í•  ìˆ˜ ìˆëŠ” ë‚ ì¹´ë¡œìš´ ì§ˆë¬¸ {num_questions}ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
            ì§ˆë¬¸ ëª©ë¡ë§Œ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”.
            ```json
            {{ "questions": ["ìƒì„±ëœ ì§ˆë¬¸ 1", "ìƒì„±ëœ ì§ˆë¬¸ 2"] }}
            ```
            """
            response = self.client.chat.completions.create(
                model=self.model, messages=[{"role": "user", "content": prompt}],
                max_tokens=1000, temperature=0.8, response_format={"type": "json_object"}
            )
            result = json.loads(extract_json_from_response(response.choices[0].message.content))
            questions = result.get("questions", [])
            print(f"âœ… {len(questions)}ê°œì˜ ë§ì¶¤ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ.")
            return questions
        except Exception as e:
            print(f"âŒ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return [f"{self.company_name}ì˜ ì£¼ìš” ê²½ìŸì‚¬ì™€ ë¹„êµí–ˆì„ ë•Œ, ìš°ë¦¬ íšŒì‚¬ê°€ ê°€ì§„ í•µì‹¬ì ì¸ ê¸°ìˆ ì  ìš°ìœ„ëŠ” ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹­ë‹ˆê¹Œ?"]

    def analyze_answer_with_rag(self, question: str, answer: str) -> dict:
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ (XAI ê¸°ë°˜, ì ìˆ˜ ì—†ìŒ)"""
        if not self.rag_ready: return {"error": "RAG ì‹œìŠ¤í…œ ë¯¸ì¤€ë¹„"}

        print(f"    (ë‹µë³€ ë¶„ì„ ì¤‘...)") # ì‚¬ìš©ìì—ê²Œ ì‹œìŠ¤í…œì´ ë™ì‘ ì¤‘ì„ì„ ì•Œë¦¬ëŠ” ìµœì†Œí•œì˜ í‘œì‹œ
        try:
            related_facts = self.rag_system.query(f"'{answer}'ë¼ëŠ” ì£¼ì¥ì— ëŒ€í•œ ì‚¬ì‹¤ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ê´€ë ¨ ë°ì´í„°ë¥¼ ì°¾ì•„ì¤˜.")
            search_results = google_search.search(queries=[f"{self.company_name} {answer}"])
            web_context = f"ì›¹ ê²€ìƒ‰ ê²°ê³¼:\n{search_results}"

            analysis_prompt = f"""
            ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì‚¬ì—… ë¶„ì„ê°€ì…ë‹ˆë‹¤. ì•„ë˜ ìë£Œë¥¼ ì¢…í•©í•˜ì—¬ ì§€ì›ìì˜ ë‹µë³€ì„ ìƒì„¸íˆ í‰ê°€í•´ì£¼ì„¸ìš”.
            **'ë°ì´í„° ê¸°ë°˜ ì‚¬ì‹¤ ë¶„ì„'ê³¼ 'ë…ì°½ì ì¸ ì „ëµì  í†µì°°ë ¥'ì„ êµ¬ë¶„í•˜ì—¬ í‰ê°€í•˜ê³ , ì ìˆ˜ ëŒ€ì‹  ì„œìˆ í˜•ìœ¼ë¡œ í‰ê°€ ì˜ê²¬ì„ ì œì‹œí•´ì£¼ì„¸ìš”.**

            **ë©´ì ‘ ì§ˆë¬¸:** {question}
            **ì§€ì›ì ë‹µë³€:** {answer}
            ---
            **[ìë£Œ 1] ë‚´ë¶€ ì‚¬ì—… ë°ì´í„°:** {related_facts}
            **[ìë£Œ 2] ì™¸ë¶€ ì›¹ ê²€ìƒ‰ ê²°ê³¼:** {web_context}
            ---
            **í‰ê°€ ì§€ì¹¨:**
            1. **ì£¼ì¥ë³„ ì‚¬ì‹¤ í™•ì¸:** ì§€ì›ìì˜ í•µì‹¬ ì£¼ì¥ì„ 1~2ê°œ ë½‘ì•„ ìë£Œ 1, 2ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê²€ì¦í•©ë‹ˆë‹¤.
            2. **ë‚´ìš© ë¶„ì„:** ë°ì´í„° í™œìš© ëŠ¥ë ¥ê³¼ ë…ì°½ì ì¸ ë¹„ì¦ˆë‹ˆìŠ¤ ë…¼ë¦¬ë¥¼ í‰ê°€í•©ë‹ˆë‹¤.
            3. **í”¼ë“œë°±:** ê°•ì ê³¼ ê°œì„  ì œì•ˆì„ ì„œìˆ í•©ë‹ˆë‹¤.
            
            **ì‘ë‹µ í˜•ì‹ (JSON):**
            ```json
            {{
                "fact_checking": [{{ "claim": "ì¶”ì¶œí•œ ì£¼ì¥", "verification": "í™•ì¸ ê²°ê³¼", "evidence": "íŒë‹¨ ê·¼ê±°" }}],
                "content_analysis": {{
                    "analytical_depth": {{ "assessment": "í‰ê°€ ì˜ê²¬ (ì˜ˆ: ë°ì´í„°ì˜ í•µì‹¬ì„ ì •í™•íˆ íŒŒì•…í•¨)", "comment": "ìƒì„¸ ì½”ë©˜íŠ¸" }},
                    "strategic_insight": {{ "assessment": "í‰ê°€ ì˜ê²¬ (ì˜ˆ: ì‹¤í˜„ ê°€ëŠ¥í•œ ë…ì°½ì  ì•„ì´ë””ì–´ ì œì‹œ)", "comment": "ìƒì„¸ ì½”ë©˜íŠ¸" }}
                }},
                "actionable_feedback": {{ "strengths": [], "suggestions_for_improvement": [] }}
            }}
            ```
            """
            response = self.client.chat.completions.create(
                model=self.model, messages=[{"role": "user", "content": analysis_prompt}],
                temperature=0.2, max_tokens=2000, response_format={"type": "json_object"}
            )
            return json.loads(extract_json_from_response(response.choices[0].message.content))
        except Exception as e:
            print(f"âŒ ë‹µë³€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {e}")
            return {"error": str(e)}

    def print_individual_analysis(self, analysis: dict, question_num: int):
        """ê°œë³„ ë‹µë³€ì— ëŒ€í•œ ë¶„ì„ ê²°ê³¼ ì¶œë ¥ í˜•ì‹"""
        if "error" in analysis:
            print(f"\nâŒ ë¶„ì„ ì˜¤ë¥˜: {analysis['error']}")
            return

        print("\n" + "="*70)
        print(f"ğŸ“Š [ì§ˆë¬¸ {question_num}] ë‹µë³€ ìƒì„¸ ë¶„ì„ ê²°ê³¼")
        print("="*70)

        print("\n" + "-"*30)
        print("âœ… ì£¼ì¥ë³„ ì‚¬ì‹¤ í™•ì¸ (Fact-Checking)")
        fact_checks = analysis.get("fact_checking", [])
        if not fact_checks: print("  - í™•ì¸ëœ ì£¼ì¥ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            for check in fact_checks:
                print(f"  - ì£¼ì¥: \"{check.get('claim', 'N/A')}\"")
                print(f"    - ê²€ì¦: {check.get('verification', 'N/A')}")
                print(f"    - ê·¼ê±°: {check.get('evidence', 'N/A')}")

        print("\n" + "-"*30)
        print("ğŸ“ ë‚´ìš© ë¶„ì„ (Content Analysis)")
        content = analysis.get("content_analysis", {})
        depth = content.get("analytical_depth", {})
        insight = content.get("strategic_insight", {})
        print(f"  - ë°ì´í„° ë¶„ì„ ê¹Šì´: {depth.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {depth.get('comment', 'N/A')}")
        print(f"  - ì „ëµì  í†µì°°ë ¥: {insight.get('assessment', 'N/A')}")
        print(f"    - ì½”ë©˜íŠ¸: {insight.get('comment', 'N/A')}")
        
        print("\n" + "-"*30)
        print("ğŸ’¡ ì‹¤í–‰ ê°€ëŠ¥í•œ í”¼ë“œë°± (Actionable Feedback)")
        feedback = analysis.get("actionable_feedback", {})
        strengths = feedback.get("strengths", [])
        suggestions = feedback.get("suggestions_for_improvement", [])
        if strengths:
            print("  - ê°•ì :")
            for s in strengths: print(f"    âœ“ {s}")
        if suggestions:
            print("  - ê°œì„  ì œì•ˆ:")
            for s in suggestions: print(f"    â†’ {s}")
        print("="*70)

    def generate_follow_up_question(self, original_question: str, answer: str, analysis: dict) -> str:
        """ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‹¬ì¸µ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„±"""
        try:
            suggestions = analysis.get("actionable_feedback", {}).get("suggestions_for_improvement", [])
            prompt = f"ê¸°ì¡´ ì§ˆë¬¸: {original_question}\nì§€ì›ì ë‹µë³€: {answer}\në‹µë³€ì— ëŒ€í•œ AI ë¶„ì„ ë‚´ìš©(ê°œì„  ì œì•ˆ): {', '.join(suggestions)}\n\nìœ„ ìƒí™©ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì˜ ë…¼ë¦¬ë¥¼ ë” ê¹Šê²Œ íŒŒê³ ë“¤ê¸° ìœ„í•œ í•µì‹¬ ê¼¬ë¦¬ ì§ˆë¬¸ 1ê°œë§Œ JSON í˜•ì‹ìœ¼ë¡œ ìƒì„±í•´ì£¼ì„¸ìš”. (ì˜ˆ: {{\"follow_up_question\": \"ìƒì„±ëœ ê¼¬ë¦¬ ì§ˆë¬¸\"}})"
            response = self.client.chat.completions.create(
                model=self.model, messages=[{"role": "user", "content": prompt}],
                temperature=0.7, max_tokens=300, response_format={"type": "json_object"}
            )
            result = json.loads(extract_json_from_response(response.choices[0].message.content))
            return result.get("follow_up_question", "")
        except Exception as e:
            print(f"âŒ ê¼¬ë¦¬ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {e}")
            return ""

    def conduct_interview(self):
        """[ìˆ˜ì •] í‰ê°€ ê²°ê³¼ëŠ” ë©´ì ‘ ì¢…ë£Œ í›„ ì¼ê´„ ì¶œë ¥"""
        if not self.rag_ready:
            print("\nâŒ RAG ì‹œìŠ¤í…œì´ ì¤€ë¹„ë˜ì§€ ì•Šì•„ ë©´ì ‘ì„ ì§„í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            return

        questions = self.generate_questions()
        if not questions:
            print("\nâŒ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")
            return

        print("\n" + "="*70)
        print(f"ğŸ¢ {self.company_name} {self.job_title} ì§ë¬´ ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")
        print("ë©´ì ‘ì´ ì¢…ë£Œëœ í›„ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ì´ ì œê³µë©ë‹ˆë‹¤.")
        print("="*70)

        interview_transcript = []

        for i, question in enumerate(questions, 1):
            print(f"\n--- [ì§ˆë¬¸ {i}/{len(questions)}] ---")
            print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {question}")
            answer = input("ğŸ’¬ ë‹µë³€: ")
            if answer.lower() in ['/quit', '/ì¢…ë£Œ']: break

            # [í•µì‹¬] í‰ê°€ëŠ” ìˆ˜í–‰í•˜ë˜, ê²°ê³¼ëŠ” ì¶œë ¥í•˜ì§€ ì•Šê³  ì €ì¥ë§Œ í•¨
            analysis = self.analyze_answer_with_rag(question, answer)
            
            follow_up_question = ""
            follow_up_answer = ""
            if "error" not in analysis:
                follow_up_question = self.generate_follow_up_question(question, answer, analysis)
                if follow_up_question:
                    print(f"\n--- [ê¼¬ë¦¬ ì§ˆë¬¸] ---")
                    print(f"ğŸ‘¨â€ğŸ’¼ ë©´ì ‘ê´€: {follow_up_question}")
                    follow_up_answer = input("ğŸ’¬ ë‹µë³€: ")

            # í˜„ì¬ ì§ˆë¬¸, ë‹µë³€, ë¶„ì„ ë‚´ìš©, ê¼¬ë¦¬ ì§ˆë¬¸/ë‹µë³€ì„ ëª¨ë‘ ê¸°ë¡
            interview_transcript.append({
                "question_num": i, "question": question, "answer": answer, "analysis": analysis,
                "follow_up_question": follow_up_question, "follow_up_answer": follow_up_answer
            })

        print("\nğŸ‰ ë©´ì ‘ì´ ì¢…ë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ìˆ˜ê³ í•˜ì…¨ìŠµë‹ˆë‹¤.")
        
        # [í•µì‹¬] ë©´ì ‘ ì¢…ë£Œ í›„, ì €ì¥ëœ ëª¨ë“  ë¶„ì„ ê²°ê³¼ë¥¼ ì¼ê´„ ì¶œë ¥
        if interview_transcript:
            print("\n\n" + "#"*70)
            print(" ë©´ì ‘ ì „ì²´ ë‹µë³€ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë¦¬í¬íŠ¸")
            print("#"*70)

            # 1. ê°œë³„ ë‹µë³€ ë¶„ì„ ê²°ê³¼ë¶€í„° ìˆœì„œëŒ€ë¡œ ì¶œë ¥
            for item in interview_transcript:
                self.print_individual_analysis(item['analysis'], item['question_num'])

            # 2. ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ë° ì¶œë ¥
            self.generate_final_report(interview_transcript)

    def generate_final_report(self, transcript: list):
        """ë©´ì ‘ ì „ì²´ ê¸°ë¡ì„ ë°”íƒ•ìœ¼ë¡œ ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„±"""
        print("\n\n" + "#"*70)
        print(" ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        print("#"*70)
        
        try:
            # ë©´ì ‘ ì „ì²´ ëŒ€í™” ë‚´ìš©ê³¼ ê°œë³„ ë¶„ì„ ê²°ê³¼ë¥¼ ìš”ì•½í•˜ì—¬ í”„ë¡¬í”„íŠ¸ì— ì „ë‹¬
            conversation_summary = ""
            for item in transcript:
                q_num = item['question_num']
                analysis_assessment = item['analysis'].get('content_analysis', {}).get('strategic_insight', {}).get('assessment', 'ë¶„ì„ ë¯¸ì™„ë£Œ')
                conversation_summary += f"ì§ˆë¬¸ {q_num}: {item['question']}\në‹µë³€ {q_num}: {item['answer']}\n(ê°œë³„ ë¶„ì„ ìš”ì•½: {analysis_assessment})\n---\n"

            report_prompt = f"""
            ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ ì±„ìš© ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì•„ë˜ì˜ ì „ì²´ ë©´ì ‘ ëŒ€í™” ë° ê°œë³„ ë¶„ì„ ìš”ì•½ì„ ì¢…í•©í•˜ì—¬, ì§€ì›ìì— ëŒ€í•œ 'ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸'ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
            
            **[ìë£Œ] ë©´ì ‘ ì „ì²´ ìš”ì•½:**
            {conversation_summary}
            ---
            **ë¦¬í¬íŠ¸ ì‘ì„± ì§€ì¹¨:**
            1. **ì¢…í•© ì´í‰:** ì§€ì›ìì˜ ì¼ê´€ì„±, ê°•ì , ì•½ì ì„ ì¢…í•©í•˜ì—¬ ìµœì¢… í‰ê°€ë¥¼ ë‚´ë¦½ë‹ˆë‹¤.
            2. **í•µì‹¬ ì—­ëŸ‰ ë¶„ì„:** {self.job_title} ì§ë¬´ì— í•„ìš”í•œ í•µì‹¬ ì—­ëŸ‰(ì˜ˆ: ë¬¸ì œ í•´ê²° ëŠ¥ë ¥, ë¹„ì¦ˆë‹ˆìŠ¤ ì´í•´ë„, ê¸°ìˆ  ì „ë¬¸ì„±) 3ê°€ì§€ë¥¼ ì‹ë³„í•˜ê³ , ë©´ì ‘ ì „ì²´ ë‚´ìš©ì„ ê·¼ê±°ë¡œ [ìµœìƒ], [ìƒ], [ì¤‘], [í•˜]ë¡œ í‰ê°€í•©ë‹ˆë‹¤. ê° í‰ê°€ì— ëŒ€í•œ êµ¬ì²´ì ì¸ ê·¼ê±°ë¥¼ ì œì‹œí•´ì•¼ í•©ë‹ˆë‹¤.
            3. **ì„±ì¥ ê°€ëŠ¥ì„±:** ë©´ì ‘ ê³¼ì •ì—ì„œ ë³´ì¸ íƒœë„ë‚˜ ë‹µë³€ì˜ ê¹Šì´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ ì ì¬ë ¥ì„ í‰ê°€í•©ë‹ˆë‹¤.

            **ì‘ë‹µ í˜•ì‹ (JSON):**
            ```json
            {{
                "overall_summary": "ì¢…í•©ì ì¸ í‰ê°€ ìš”ì•½...",
                "core_competency_analysis": [
                    {{"competency": "í•µì‹¬ ì—­ëŸ‰ 1", "assessment": "[í‰ê°€ ë“±ê¸‰]", "evidence": "íŒë‹¨ ê·¼ê±°..."}}
                ],
                "growth_potential": "ì§€ì›ìì˜ ì„±ì¥ ê°€ëŠ¥ì„±ì— ëŒ€í•œ ì½”ë©˜íŠ¸..."
            }}
            ```
            """
            response = self.client.chat.completions.create(
                model=self.model, messages=[{"role": "user", "content": report_prompt}],
                temperature=0.3, max_tokens=3000, response_format={"type": "json_object"}
            )
            report_data = json.loads(extract_json_from_response(response.choices[0].message.content))
            self.print_final_report(report_data)

        except Exception as e:
            print(f"âŒ ìµœì¢… ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            traceback.print_exc()

    def print_final_report(self, report: dict):
        """ìµœì¢… ì¢…í•© ë¦¬í¬íŠ¸ ì¶œë ¥"""
        if not report: return
        
        print("\n\n" + "="*70)
        print(f"ğŸ… {self.company_name} {self.job_title} ì§€ì›ì ìµœì¢… ì—­ëŸ‰ ë¶„ì„ ì¢…í•© ë¦¬í¬íŠ¸")
        print("="*70)

        print(f"\nâ–  ì´í‰ (Overall Summary)\n" + "-"*50)
        print(report.get("overall_summary", "ìš”ì•½ ì •ë³´ ì—†ìŒ."))

        print(f"\nâ–  í•µì‹¬ ì—­ëŸ‰ ë¶„ì„ (Core Competency Analysis)\n" + "-"*50)
        for comp in report.get("core_competency_analysis", []):
            print(f"  - {comp.get('competency', 'N/A')}: **{comp.get('assessment', 'N/A')}**")
            print(f"    - ê·¼ê±°: {comp.get('evidence', 'N/A')}")
        
        print(f"\nâ–  ì„±ì¥ ê°€ëŠ¥ì„± (Growth Potential)\n" + "-"*50)
        print(f"  {report.get('growth_potential', 'N/A')}")
        print("\n" + "="*70)

def main():
    try:
        target_container = 'interview-data'
        company_name = input("ë©´ì ‘ì„ ì§„í–‰í•  íšŒì‚¬ ì´ë¦„ (ì˜ˆ: SKí•˜ì´ë‹‰ìŠ¤): ")
        safe_company_name_for_index = unidecode(company_name.lower()).replace(' ', '-')
        index_name = f"{safe_company_name_for_index}-report-index"
        job_title = input("ì§€ì› ì§ë¬´ (ì˜ˆ: ì‚¬ì—…ë¶„ì„ê°€): ")

        print("\n" + "-"*40)
        print(f"ëŒ€ìƒ ì»¨í…Œì´ë„ˆ: {target_container}")
        print(f"íšŒì‚¬ ì´ë¦„: {company_name}")
        print(f"AI Search ì¸ë±ìŠ¤: {index_name}")
        print("-"*40)

        bot = RAGInterviewBot(company_name=company_name, job_title=job_title, container_name=target_container, index_name=index_name)
        bot.conduct_interview()

    except Exception as e:
        print(f"\nâŒ ì‹œìŠ¤í…œ ì‹¤í–‰ ì¤‘ ì‹¬ê°í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        traceback.print_exc()

if __name__ == "__main__":
    main()